---
title: |
  | Financial Econometrics Analysis on S&P-500 Returns (Jan 1980 - Dec 2008) and US Quarterly GDP Growth Rate (Q1 1955 - Q4 2004)
author: |
  | Zhiyu Chen
  | Imperial College London
  | CID: 02517659
date: "02-12-2023"
output: 
  pdf_document:
    latex_engine: xelatex
header-includes:
  - \usepackage[utf8]{inputenc}
---

\newpage
\tableofcontents
\newpage

## Loading R packages

```{r loadLibs, message=FALSE, warning=FALSE}
library(readxl)
library(stats)
library(sandwich)
library(lmtest)
library(rugarch)
library(fGarch)
library(dplyr)
library(forecast)
library(fUnitRoots)
```

## Dataset 1 - SP500WeekDays

This dataset contains the daily simple returns of the S&P 500 composite index from January 1980 to December 2008. The index returns include dividend distributions. The data file is S&P500WeekDays which has 9 columns. The columns are (year, month, day, SP, M, T, W, H, F), where M, T, W, H, F denotes indicator variables for Monday to Friday, respectively.

### Multiple Linear Regression Model on Weekday Effects

Use a regression model to study the effects of trading days on the index returns. The fitted model is Multiple Linear Regression model because thee are more than one independent variable (in this case, M, T, W, H, F are all independent variables.)

So the model should be:
SP Return=β0+β1·Monday+β2·Tuesday+β3·Wednesday+β4·Thursday+β5·Friday+ϵ

where β0 is the intercept, β1 to β5 are the coefficients for the weekday indicators, and ϵ is the error term.

```{r Fit the Multiple Linear Regression Model}
data <- read_excel("SP500WeekDays.xlsx")
data <- na.omit(data)

# The dependent variable: S&P 500 daily returns
y <- data$sp

# The independent variable: indicators for the weekdays
X <- data[, c('M', 'T', 'W', 'R', 'F')]

# Fit the linear regression model
model <- lm(y ~ M + T + W + R + F, data = data)

# This shows the summary of the model
summary(model)
```
As the sum of dummy from Monday to Friday equals one, it results in the NA of one of the five variables. To refit the model, We just need to omit one day among the five weekdays. In this occasion, we omit F (Friday).

```{r Model Refit}
# Refit the model
model_refit <- lm(y ~ M + T + W + R, data = data)
summary(model_refit)

# Extract the p-values
p_values <- coef(summary(model_refit))[, "Pr(>|t|)"]
p_values
```

The re-fitted model is:
$$sp = -0.0003290 + (-0.0003711)·M + 0.0004114·T + 0.0003108·W + (-0.0002646)·R$$

The p-values for the coefficients of Monday, Tuesday, Wednesday, and Thursday are 0.375, 0.317, 0.449, 0.521. None of them are statistically significant at a 5% significance level (p-value < 0.05). Thus the the weekday effects are **NOT significant** in the returns at the 5% level.

### Newey West Estimator Analysis on Weekday Effects

The Newey West Estimator provides consistent standard errors for coefficient estimates in the presence of heteroskedasticity and autocorrelation.The estimator adjusts the covariance matrix of the coefficient estimates to account for these issues, thus improving the reliability of hypothesis testing.

$$\text{Var}(\hat{\beta})_{NW} = \left( X'X \right)^{-1} \left( \sum_{t=1}^T \epsilon_t^2 X_t X_t' + \sum_{l=1}^L w_l \sum_{t=l+1}^T \epsilon_t \epsilon_{t-l} (X_t X_{t-l}' + X_{t-l} X_t') \right) \left( X'X \right)^{-1}$$

where:

- $\text{Var}(\hat{\beta})_{NW}$ is the Newey-West adjusted covariance matrix.
- $X'X$ is the product of the matrix of independent variables and its transpose.
- $\epsilon_t$ is the residual at time $t$.
- $L$ is the chosen lag length.
- $w_l$ are the weights assigned to the lagged terms.

Use the Newey West estimator of the covariance matrix to obtain the t-ratio of regression estimates.

```{r Newey West Estimator}
# Calculate Newey-West standard errors
nw_se <- NeweyWest(model_refit)

#Use coeftest to get t-ratio with Newey-West standard errors
t_ratio <- coeftest(model, vcov = nw_se)
t_ratio
```
T-ratio (t-statistic) in regression analysis is the ratio of the estimated coefficient to its standard error. It's used to test the null hypothesis that the coefficient is equal to zero. Typically, a t-ratio greater than +1.96 or less than -1.96 is considered statistically significant at the 5% level.

In this occasion, t-value for Monday is -0.8679, for Tuesday is 1.0674, for Wednesday is 0.8042 and for Thursday if -0.6848. No t-value satisfies greater than +1.96 or less than -1.96, so the Newey West estimator **does NOT change** the conclusion of weekday effect, that weekday effects are not significant in the returns at the 5% level.

### The ARCH(1) and GARCH(1,1) Models for the log Returns

The Autoregressive Conditional Heteroskedasticity (ARCH), is a statistical model used to describe and predict time series data, particularly the volatility of financial time series. 

$$\sigma_t^2 = \alpha_0 + \alpha_1 \epsilon_{t-1}^2$$

The Generalized Autoregressive Conditional Heteroskedasticity (GARCH), is an extension of the ARCH model. It's also widely used in financial econometrics to model time series data, particularly for capturing the volatility (time-varying variance) of financial returns.

$$\sigma^2_t = \alpha_0 + \alpha_1 \epsilon^2_{t-1} + \beta_1 \sigma^2_{t-1}$$

where:

- $\sigma^2_t$ is the conditional variance at time $t$.
- $\alpha_0$ is a constant term, representing the long-run average variance.
- $\alpha_1$ is the coefficient for the lagged squared error term, representing the impact of short-term shocks on current volatility.
- $\epsilon^2_{t-1}$ is the squared error term (or residual) from the previous time period.
- $\beta_1$ is the coefficient for the lagged conditional variance, indicating the persistence of volatility over time.
- $\sigma^2_{t-1}$ is the conditional variance from the previous time period.

Firstly, fit the ARCH(1) and GARCH (1,1) for the SP_500 log returns.

For ARCH(1), set up a standard GARCH model which, with garchOrder "c(1,0)", becomes an ARCH(1) model as the GARCH term is set to 0.

For GARCH(1,1), set up a standard GARCH model which, with garchOrder "c(1,1)".
```{r Fit ARCH(1) and GARCH(1,1)}
# Calculate the log returns
log_returns <- log(1 + data$sp)
log_returns <- na.omit(log_returns)

# Fit an ARCH(1) model
arch <- garchFit(~ garch(1, 0), data = log_returns, trace = FALSE)
summary(arch)

# Fit a GARCH(1,1) model
garch <- garchFit(~ garch(1, 1), data = log_returns, trace = FALSE)
summary(garch)

```
For the ARCH(1), the p-value for coefficient mu(mean) is 0.00029, omega(variance constant) is less than 2e-16 and alpha1(ARCH term) is less than 2e-16. These three p-values are extremely small and thus, have a significant impact on the model. **The three coefficients for ARCH(1) are highly statistically significant.**

|  | value | p-value |
|---------|---------|---------|
| mu | 4.214e-04 | 0.00029 |
| omega | 8.727e-05 | < 2e-16 |
| alpha1 | 2.900e-01 | < 2e-16 |

For the GARCH(1,1), the p-value for coefficient mu(mean) is 5.39e-08, omega(variance constant) is 2.58e-08, alpha1(short-term GARCH term) is less than 2e-16 and beta1(long-term GARCH term) is less than 2e-16. These four p-values are extremely small and thus, also have a significant impact on the model. **The four coefficients for GARCH(1,1) are highly statistically significant.**

|  | value | p-value |
|---------|---------|---------|
| mu | 5.215e-04 | 5.39e-08 |
| omega | 1.198e-06 | 2.58e-08 |
| alpha1 | 7.398e-02 | < 2e-16 |
| beta1 | 9.177e-01 | < 2e-16 |

```{r Compute the Unconditional Variance log returns ARCH(1) and GARCH(1,1)}
# Extract coefficients for ARCH(1) model and 
# Compute the unconditional variance
omega_arch <- coef(arch)["omega"]
alpha_arch <- coef(arch)["alpha1"]
uncond_var_arch <- omega_arch / (1 - alpha_arch)

# Extract the coefficients for GARCH(1,1) model and
# Compute the unconditional variance
omega_garch <- coef(garch)["omega"]
alpha_garch <- coef(garch)["alpha1"]
beta_garch <- coef(garch)["beta1"]
uncond_var_garch <- omega_garch / (1 - alpha_garch - beta_garch)

# Print the unconditional variance for the two models
round(uncond_var_arch,6)
round(uncond_var_garch,6)
```
The unconditional variance measures the average level of variance (or volatility) that can be expected over a long period.

$$
\text{Unconditional Variance} = \frac{\alpha_0}{1 - \alpha_1 - \beta_1}
$$

Where:

- $\alpha_0$ represents the constant term in the GARCH(1,1) model.
- $\alpha_1$ is the coefficient for the lagged error term, $e_{t-1}^2$.
- $\beta_1$ is the coefficient for the lagged variance term, $\sigma_{t-1}^2$.

**The unconditional variance given by ARCH(1) is 0.000123, and by GARCH(1,1) is 0.000144.**

**The high significance of alpha1 and beta1 in GARCH(1,1) indicates that SP500 log returns are greatly affected by both short-term shocks and long-term volatility.**

The higher unconditional variance from the GARCH(1,1) compared to the ARCH(1) indicates that GARCH model estimates a higher long-term average volatility for the SP-500 log return from January 1980 to December 2008. The GARCH(1.1) captures a higher level of volatility might be due to its structure that accounts for both volatility clustering and mean reversion in volatility, while ARCH(1) is simpler and only focusing on the immediate past volatility, which may not fully capture the persistence in volatility that GARCH(1,1) can.

\newpage

## Dataset 2 - USMacro_Quarterly

This dataset contains quarterly data on two macroeconomic series for the United States: 

1. RealGDP: The quarterly values of Real GDP for the United States, expressed in billions of chained (2000) dollars. The data is seasonally adjusted at an annual rate.. 

2. TBillRate: The quarterly values of the rate on 3-month Treasury Bills. The values are quarterly averages of daily rates, expressed in percentage points at an annual rate.

The logarithm of real GDP: Y(t) = ln[GDP(t)]
The quarterly growth rate of GDP: ΔY(t)

Sample period 1955:1 - 2004:4 is used.

### Estimation of the Mean of ΔY(t)

```{r Estimation of the Mean of ΔY(t)}
# Read the dataset
data_US <- read_excel("USMacro_Quarterly.xls")

# Convert "Date" to a year-quarter format
data_US$Date <- as.yearqtr(data_US$Date, format = "%Y:%q")

# Calculate the logarithm of Real GDP
# Calculate the quarterly growth rate of GDP (ΔY(t))
data_US <- data_US %>%
  mutate(Log_RealGDP = log(RealGDP)) %>%
  mutate(GDP_Growth_Rate = Log_RealGDP - lag(Log_RealGDP))
  
# Filter for the sample period from 1955:1 to 2004:4
start_period <- as.yearqtr("1955 Q1", format = "%Y Q%q")
end_period <- as.yearqtr("2004 Q4", format = "%Y Q%q")
sample_data <- data_US %>%
  filter(Date >= start_period & Date <= end_period)

# Compute the mean of the GDP Growth Rate (na.rm=TRUE to ignore NA values)
mean_gdp_growth_rate <- mean(sample_data$GDP_Growth_Rate, na.rm = TRUE)
mean_gdp_growth_rate
```
The quarter mean of GDP growth rate is **0.00826**

### The Mean Growth Rate in Percentage Points at Annual Rate

To express the mean growth rate in percentage points at an annual rate, multiply the quarterly mean growth rate by 400. (Quarterly to annualy: x4; Decimal form to percentage form: x100)

```{r Reformat The GDP Mean Growth Rate}
# Get the mean growth rate in percentage points at annual rate
annual_mean_gdp_growth_rate <- mean_gdp_growth_rate * 400
annual_mean_gdp_growth_rate
```
The annual mean of GDP growth rate is **3.30%**

### Estimation of the Standard Deviation of ΔY(t)

The result is in percentage points at an annual rate.

```{r Estimation of the Standard Deviation of ΔY(t)}
# Compute the standard deviation of the GDP Growth Rate (ΔY(t))
std_dev_gdp_growth_rate <- sd(sample_data$GDP_Growth_Rate, na.rm = TRUE)

# Convert the result in % points at annual rate
annual_std_dev_gdp_growth_rate <- std_dev_gdp_growth_rate * 400
annual_std_dev_gdp_growth_rate
```
The annual standard deviation of GDP growth rate is **3.68%**

### Estimation of the First Four Autocorrelations of ΔY(t)

```{r Estimation of the First Four Autocorrelations of ΔY(t)}
# The autocorrelations of ΔY(t)
autocorrelations <- Acf(sample_data$GDP_Growth_Rate, lag.max = 4, plot = T)

# Find the first four autocorrelations
autocorr_4 <- autocorrelations$acf[2:5]
autocorr_4
```
After omitting the autocorrelation of exactly itself(Lag=0 and the ACF value must be 1), **the fist four autocorrelations are: 0.2894(Lag=1), 0.1711(Lag=2), 0.0230(Lag=3) and -0.0240(Lag=4).** Autocorrelations do not have units as they are statistical measures that quantify the degree of correlation between a time series and the lagged versions of itself. These coefficients are expressed as values between -1 and +1, regardless of the units of the original data.

### AR(1) Model Estimation for ΔY(t)

The Autoregression model of order 1 (AR(1) model), is a basic yet widely used time series model that explains a variable in terms of its own previous value. The AR(1) model is characterized by a single lagged term of the variable.

$$Y_t = \mu + \phi Y_{t-1} + \epsilon_t$$

where:

- $Y_t$ is the value of the time series at time $t$.
- $\mu$ is the constant term or intercept.
- $\phi$ is the autoregressive coefficient for the first lag of the series.
- $Y_{t-1}$ is the value of the series at the previous time step.
- $\epsilon_t$ is the error term, representing random fluctuations that cannot be explained by the model.

Estimate an AR(1) model for ΔY(t). The Arima() function is used to fit an AR(1) model, specified by 'order = c(1,0,0)'

```{r Fit an AR(1) Model for ΔY(t)}
# Fit the AR(1)
ar1_model <- arima(sample_data$GDP_Growth_Rate, order=c(1,0,0))
ar1_model

summary(ar1_model)

# Extract the estimated AR(1) coefficient
ar1_coefficient <- ar1_model$coef[1]
ar1_coefficient
```
**The estimated AR(1) coefficient is 0.2951.** To determine whether the estimated AR(1) coefficient is statistically significantly different from zero, calculate the t-statistic and the corresponding p-value for this coefficient in the output of AR(1) model.

```{r Calculate t-statistic & p-value for AR(1) Coefficient}
# Extract standard error from the model
ar1_se <- sqrt(diag(vcov(ar1_model)))[1]

# Calculate the t-statistic
t_statistic_ar1 <- ar1_coefficient / ar1_se
t_statistic_ar1

# Calculate the degrees of freedom for the t-distribution
df <- length(sample_data$GDP_Growth_Rate) - ar1_model$arma[1] - 1

# Calculate the two-tailed p-value
p_value_ar1 <- 2 * pt(-abs(t_statistic_ar1), df)
p_value_ar1
```
For the AR(1) coefficient, the absolute value of t-statistic is 4.3260 (larger than 2) and the p-value is 0.000024 (less than 0.05), so it is commonly considered statistically significant at the 5% level (95% confidence interval), indicating that **AR(1) coefficient is significantly different from zero.**

### AR(2) Model Estimation for ΔY(t)

The Autoregressive model of order 2 (AR(2) model), is a time series model where the current value of the series is explained by its own two previous values. This model is useful when the data shows evidence of being influenced by the last two periods.

$$Y_t = \mu + \phi_1 Y_{t-1} + \phi_2 Y_{t-2} + \epsilon_t$$

where:

- $Y_t$ is the value of the time series at time $t$.
- $\mu$ is the constant term or intercept.
- $\phi_1$ and $\phi_2$ are the autoregressive coefficients for the first and second lags of the series.
- $Y_{t-1}$ and $Y_{t-2}$ are the values of the series at the previous two time steps.
- $\epsilon_t$ is the error term, representing random fluctuations that cannot be explained by the model.

Estimate an AR(2) model for ΔY(t). The Arima() function is used to fit an AR(2) model, specified by 'order = c(2,0,0)'

```{r Fit an AR(2) Model for ΔY(t)}
# Fit the AR(2)
ar2_model <- arima(sample_data$GDP_Growth_Rate, order=c(2,0,0))
ar2_model

# Extract the estimated coefficients for the two lags
ar2_coefficient <- ar2_model$coef[2]
ar2_coefficient
```
**The estimated AR(2) coefficient is 0.0979.** To determine whether it is statistically significantly different from zero, calculate the t-statistic and p-value

```{r Calculate t-statistic & p-value for AR(2) Coefficient}
# Extract standard error from the model
ar2_se <- sqrt(diag(vcov(ar2_model)))[2]

# Calculate the t-statistic
t_statistic_ar2 <- ar2_coefficient / ar2_se
t_statistic_ar2

# Calculate the degrees of freedom for the t-distribution
df <- length(sample_data$GDP_Growth_Rate) - ar2_model$arma[1] - 1

# Calculate the two-tailed p-value
p_value_ar2 <- 2 * pt(-abs(t_statistic_ar2), df)
p_value_ar2
```
For the AR(2) coefficient, the absolute value of t-statistic is 1.3807 (not larger than 2) and the p-value is 0.1689 (not less than 0.05), so it is commonly considered NOT statistically significant at the 5% level (95% confidence interval), indicating that **AR(2) coefficient is NOT significantly different from zero.**

Based on the calculation, AR(1) coefficient is statistically significant at 95% confidence interval while AR(2) coefficient is not. So AR(1) model is more justified than AR(2) model for ΔY(t). The lack of statistical significance of the AR(2) coefficient suggests that adding the second lag does not provide additional explanatory power to the model that is statistically meaningful.

### AR(3) Model Estimation for ΔY(t)

Estimate an AR(3) model for ΔY(t). The Arima() function is used to fit an AR(3) model, specified by 'order = c(3,0,0)'

```{r Fit an AR(3) model for ΔY(t)}
# Fit the AR(3)
ar3_model <- arima(sample_data$GDP_Growth_Rate, order=c(3,0,0))
ar3_model
```

### AR(4) Model Estimation for ΔY(t)

Estimate an AR(4) model for ΔY(t). The Arima() function is used to fit an AR(4) model, specified by 'order = c(4,0,0)'

```{r Fit an AR(4) model for ΔY(t)}
# Fit the AR(4)
ar4_model <- arima(sample_data$GDP_Growth_Rate, order=c(4,0,0))
ar4_model
```

### AR(1)-AR(4) Bayesian Information Criterion (BIC) Model Selection Methodology

The Bayesian Information Criterion (BIC), is a criterion for model selection among a finite set of models. It is based on the likelihood function and is used extensively in statistical model fitting.

$$\text{BIC} = \ln(n)k - 2\ln(\hat{L})$$

where:

- $n$ is the number of observations.
- $k$ is the number of parameters in the model.
- $\ln$ is the natural logarithm.
- $\hat{L}$ is the maximized value of the likelihood function of the model.

In model selection, the model with the lowest BIC is generally preferred. The lower BIC suggests either a better fit, fewer parameters, or both.

```{r AR(1)-AR(4) BIC}
# Extract BIC values
bic_values <- c(BIC(ar1_model),
                BIC(ar2_model),
                BIC(ar3_model),
                BIC(ar4_model))
bic_values

# Determine the optimal number of lags
optimal_lags_bic <- which.min(bic_values)
optimal_lags_bic
```
As AR(1) has the lowest BIC values, **the optimal number of lags in the AR model according to the BIC criterion is 1.**

### AR(1)-AR(4) Akaike Information Criterion (AIC) Model Selection Methodology

The Akaike Information Criterion (AIC), is used to compare different models and select the one that best explains the data while avoiding overfitting. It balances the model's complexity against its goodness of fit.

$$\text{AIC} = 2k - 2\ln(\hat{L})$$

where:

- $k$ is the number of parameters in the model.
- $\ln(\hat{L})$ is the natural logarithm of the maximized likelihood function of the model.

In model selection, the model with the lowest AIC is generally preferred. The lowest AIC value among a set of models indicates the model that best balances the fit to the data and the complexity of the model.

```{r AR(1)-AR(4) AIC}
# Extract BIC values
aic_values <- c(AIC(ar1_model),
                AIC(ar2_model),
                AIC(ar3_model),
                AIC(ar4_model))
aic_values

# Determine the optimal number of lags
optimal_lags_aic <- which.min(aic_values)
optimal_lags_aic
```
As AR(1) has the lowest AIC values, **the optimal number of lags in the AR model according to the AIC criterion is also 1.**

### The Augmented Dickey-Fuller (ADF) Test for ΔY(t)

The Augmented Dickey-Fuller (ADF), tests for a unit root in the time series. This test can help determine whether a time series is stationary or not, which is a critical aspect of many time series analyses, including AR modeling.

$$\Delta Y_t = \alpha + \beta t + \gamma Y_{t-1} + \delta_1 \Delta Y_{t-1} + \delta_2 \Delta Y_{t-2} + \cdots + \delta_p \Delta Y_{t-p} + \epsilon_t$$

where:

- $\Delta Y_t$ is the first difference of the series at time $t$.
- $\alpha$ is the constant term.
- $\beta t$ is the coefficient of the time trend.
- $\gamma$ is the coefficient on the lagged level of the series. The null hypothesis of the ADF test is that this coefficient is zero (indicating a unit root).
- $\delta_1, \delta_2, \ldots, \delta_p$ are the coefficients on the lagged differences of the series.
- $\epsilon_t$ is the error term.

In this scenario the ΔY(t) is expected to be stationary around a deterministic trend. In addition, choose lags = 1 because from the previous BIC and AIC model selection, AR(1) performs the best.

```{r ADF test for ΔY(t)}
# Applying the ADF test
adfTest(sample_data$GDP_Growth_Rate,lags = 1,type = c("c"))
```

The null hypothesis of ADF is that there is a unit root (implying non-stationarity). The outcome shows that the p-value of the ADF test is smaller than 0.01 (less than 0.05), suggesting rejecting the null hypothesis of a unit autoregression root, indicating that **ΔY(t) is stationary.**

### The ARCH(1) and GARCH(1,1) Models for ΔY(t)

For ARCH(1), set up a standard GARCH model which, with garchOrder "c(1,0)", becomes an ARCH(1) model as the GARCH term is set to 0.

For GARCH(1,1), set up a standard GARCH model which, with garchOrder "c(1,1)".

```{r ARCH(1) and GARCH(1,1) for ΔY(t)}
# Fit an ARCH(1) model
arch_GDP <- garchFit(~ garch(1, 0), 
                     data = sample_data$GDP_Growth_Rate, trace = FALSE)
summary(arch_GDP)

# Fit a GARCH(1,1) model
garch_GDP <- garchFit(~ garch(1, 1), 
                      data = sample_data$GDP_Growth_Rate, trace = FALSE)
summary(garch_GDP)
```

|  | value | p-value |
|---------|---------|---------|
| mu | 8.622e-03 | < 2e-16 |
| omega | 6.403e-05 | 5.27e-12 |
| alpha1 | 2.682e-01 | 0.0418 |

For the ARCH(1), the p-value for coefficient mu(mean) is less than 2e-16, omega(variance constant) is 5.27e-12 and alpha1(ARCH term) is 0.0418. The p-values for mu and omega are extremely small, suggesting that coefficient mu and omega have a significant impact on the model. The p-value for alpha1 is 0.04 (slightly less than 0.05), means that coefficient alpha1 has impact on the model at 95% confidence interval. **In summary, the three coefficients for ARCH(1) are statistically significant.**

|  | value | p-value |
|---------|---------|---------|
| mu | 8.969e-03 | < 2e-16 |
| omega | 2.246e-06 | 0.2571 |
| alpha1 | 2.170e-01 | 0.0275 |
| beta1 | 7.744e-01 | <2e-16 |

For the GARCH(1,1), the p-value for coefficient mu(mean) is less than 2e-16, omega(variance constant) is 0.2571, alpha1(short-term GARCH term) is 0.0275 and beta1(long-term GARCH term) is less than 2e-16. The p-value for mu is extremely small, suggesting that mu has a significant impact on the model. For omega is 0.2571 (not less than 0.05), suggesting that coefficient omega have NO statically significant impact on the model at 5% significance level. The p-value for alpha1 is 0.0275 (less than 0.05), suggesting that coefficient alpha has impact on the model at 95% confidence interval. The p-value of beta1 is less than 2e-16 which is extremely small, suggesting that beta1 has a significant impact on the model. **In summary, three coefficients mu alpha1 and beta1 for GARCH(1,1) are statistically significant, while coefficient omega is not.**

```{r Compute the Unconditional Variance for ΔY(t) ARCH(1) and GARCH(1,1)}
# Extract coefficients for ARCH(1) model and 
# Compute the unconditional variance
omega_arch_GDP <- coef(arch_GDP)["omega"]
alpha_arch_GDP <- coef(arch_GDP)["alpha1"]
uncond_var_arch_GDP <- omega_arch_GDP / (1 - alpha_arch_GDP)

# Extract the coefficients for GARCH(1,1) model and 
# Compute the unconditional variance
omega_garch_GDP <- coef(garch_GDP)["omega"]
alpha_garch_GDP <- coef(garch_GDP)["alpha1"]
beta_garch_GDP <- coef(garch_GDP)["beta1"]
uncond_var_garch_GDP <- omega_garch_GDP / 
  (1 - alpha_garch_GDP - beta_garch_GDP)

# Print the unconditional variance for the two models
round(uncond_var_arch_GDP,6)
round(uncond_var_garch_GDP,6)
```
The unconditional variance measures the average level of variance (or volatility) that can be expected over a long period. **The unconditional variance given by ARCH(1) is 0.00008, and by GARCH(1,1) is 0.00026.**

**The significance of alpha1 and beta1 in GARCH(1,1) indicates that the quarterly GDP growth rate of US is affected by both short-term shocks and long-term volatility. However, the effect of long-term volatility (represent by beta1) is way more than short-term shocks (represent by alpha1).**

The higher unconditional variance from the GARCH(1,1) compared to the ARCH(1) indicates that GARCH model estimates a higher long-term average volatility for the quarterly growth rate of US GDP from 1st quarter 1955 to 4th quarter 2004. The GARCH(1.1) captures a higher level of volatility might be due to its structure that accounts for both volatility clustering and mean reversion in volatility, while ARCH(1) is simpler and only focusing on the immediate past volatility, which may not fully capture the persistence in volatility that GARCH(1,1) can.